# Scaling things up

These graphs and maps show only a fraction of what can be done with the data extracted with the proposed approach even from a single biographical collection.[For more examples of such analysis of data from a different collection, see: @RomanovTAMFIH2016] The next logical step is to study data from *all* available biographical collections—this step, however, requires even further formalization and infrastructural development.

A series of activities to this end are at the core of the Open Arabic Project which has been ongoing for the past three years, first, at Tufts University (2013–2015) and now—at Leipzig University (2015–) within the broader vision of the Open Philology and Global Philology projects led by Gregory Crane, the professor of Classics at Tufts University and the holder of the Humboldt Chair of Digital Humanities at Leipzig University. One of the major efforts of these projects is the creation of machine-actionable corpora in historical languages (e.g., *Open Greek and Latin*, *Open Persian*, *Open Arabic*) and the development of tools and methods facilitating their analysis.[^1529659805]

[^1529659805]: See, the website of the Humboldt Chair at [http://www.dh.uni-leipzig.de/](http://www.dh.uni-leipzig.de/).

*Open Arabic* is currently merging with a larger collaborative effort—*Open Islamicate Texts Initiative* (OpenITI)[^fn00020]—that brings together scholars from Leipzig University, the University of Maryland (College Park), and Aga Khan University (London), and aims to construct the first scholarly machine-actionable scholarly corpus of premodern Islamicate texts—first in Arabic and Persian, and later in other languages of the Islamic world.[^fn00021] Currently, *Open Arabic* includes several major components (at varying stages of development) that are meant to facilitate not only the large-scale analysis of Arabic biographical literature, but also of Arabic written tradition more generally.

[^fn00020]: The term ‘Islamicate’ was introduced by Marshall Hodgson to refer to all things Islamic and non-Islamic, religious and non-religious that have been produced in the part of the world that we now know as the Islamic world. See, [@HodgsonVenture1974a, pp.57–60].

[^fn00021]: For more details on the initiative, see: [`http://iti-corpus.github.io/`](http://iti-corpus.github.io/). OpenITI resources will be soon available at [`https://github.com/OpenITI`](https://github.com/OpenITI).

![Chronological distribution of authors and books in the OpenArabic Corpus.](./images/oa_only.pdf){#fig:openarabic}

At the heart of *Open Arabic* is the first instantiation of the corpus of premodern and early modern Arabic texts, based on texts collected from several online open-access collections. The corpus now includes 1,850 authors and 4,280 unique titles (740 million words; with multiple editions—1.34 billion words). However, when we compare our corpus with the data from the *Hadiyyaŧ al-ʿārifīn*, it becomes clear that despite its considerable size, it still covers only a fraction of Arabic written legacy—21% of authors and about 10% of book titles (*very provisionally, of course*).[^fn00022] The chronological distribution of authors and books (Figure {@fig:openarabic}) also makes it clear that its coverage is heavily skewed toward the earlier period. The main goals for the further development of the corpus are 1) to provide detailed machine-actionable metadata suitable for research purposes;[^fn00023] 2) to vet collected texts for quality and tag their structure; 3) to expand the corpus by incorporating new digital texts from online collections that have not been covered so far, and also by OCR-ing published editions that are out of copyright;[^fn00024] 4) to create additional instantiations of the corpus that will facilitate specific forms of computational analysis, such as, for example, text reuse detection ([`https://github.com/dasmiq/passim`](https://github.com/dasmiq/passim)), topic modeling ([`https://github.com/ThomasK81/ToPan`](https://github.com/ThomasK81/ToPan)) and stylometric analyses ([`https://github.com/computationalstylistics/stylo`](https://github.com/computationalstylistics/stylo)).

The entire corpus is available at [`https://github.com/OpenArabic`](https://github.com/OpenArabic); it is organized in compliance with the standards of *canonical text services* (CTS) as implemented in the `CapiTainS Suite`. The `CapiTainS Suite` has been developed for the maintenance of textual data at the Perseus Digital Library (Tufts University) as an important step toward Linked Open Data. These standards also make our corpus easy to expand.[^fn00025]

[^fn00022]: How the data from the *Hadiyyaŧ al-ʿārifīn* correlates with what had been published is impossible to say since to date no one has conducted a study of how many books written in the Islamic world have been published so far.

[^fn00023]: Unfortunately, metadata created by librarians (for example, from [`http://www.worldcat.org/`](http://www.worldcat.org/)) is not suitable for research purposes mainly because of the complexities of the traditional Arab/Islamic name, where its six major components are used interchangeably without any consistent logic; book titles pose similar issues. Although designed to solve issues of this kind, *Virtual International Authority File* ([`https://viaf.org/`](https://viaf.org/)) is of no help here.

[^fn00024]: Building on the foundational open-source OCR work of the Leipzig University’s (LU) Alexander von Humboldt Chair for Digital Humanities, the OpenITI team has achieved accuracy rates for classical Arabic-script texts in the high nineties. On the results, see our working paper: Benjamin Kiessling, Matthew Thomas Miller, Sarah Bowen Savant, Maxim Romanov. “Important New Developments in Arabographic Optical Character Recognition (OCR)” at [https://www.academia.edu/28923960/](https://www.academia.edu/28923960/). We are currently working on a web-interface for our OCR software.

[^fn00025]: *CapiTainS Suite* was originally developed by Thibault Clérice (Leipzig University) and Bridget Almas (Tufts University). For more information, see: [`http://capitains.github.io/`](http://capitains.github.io/pages/guidelines).

We have developed a lightweight tagging scheme—`OpenArabic mARkdown`—to facilitate the conversion of raw texts into machine-actionable formats as well as to facilitate data collection and extraction. Two main issues prompted the development of the scheme. First, to avoid problems that one faces when paired symbols (such as angle brackets), left-to-right and right-to-left languages, and connected scripts[^fn00026] occur in the same document, making even a simple editing task overly complicated. Second, a lightweight and easy-to-use tagging scheme is of utmost necessity when one has to work with multivolume texts that make up the core of the Arabic written tradition.[^fn00027] Currently, `OpenArabic mARkdown` offers an easy-to-use scheme for structural tagging (3-6 symbols per tag) and a limited number of tags for semantic patterns and entities. The detailed description of the scheme can be found at [`https://alraqmiyyat.github.io/mARkdown/`](https://alraqmiyyat.github.io/mARkdown/). It can be downloaded and used in `EditPad Pro` ([`https://www.editpadpro.com/`](https://www.editpadpro.com/)).

[^fn00026]: In comparison with Hebrew, the issues with Arabic are further aggravated by the fact that the computer dynamically changes the shape of each letter depending on its place in a word—and does that for all the letters. This creates a lot of issues on all operating systems and finding an editor that can properly handle this dynamic letter form selection and display is quite a challenging task. For example, none of the major text editors for Mac offer proper support for Arabic script (which affects most of the languages of the Islamic world—Arabic, Persian, Urdu, pre-reform Turkic languages, etc.).

[^fn00027]: For example, the longest biographical collection, “The History of Damascus” (*Taʾrīḫ [madīnaŧ] Dimašq*) of Ibn ʿAsākir’s (d. 571/1175 CE), is a 70-volume book of 10 million words; there almost two hundred books over 1-million word threshold.

Additionally, we are developing a `Python` library ([`pyoa`](https://pypi.python.org/pypi/pyoa)) that will facilitate algorithmic analysis and conversion routines (for example, from `OpenArabic mARkdown` to TEI XML), as well as the work with *Open Arabic* more generally. Last but not least, we are working on an `exploratorium` (in D3) that will allow users to explore abstractions of biographical collections through a series of interactive data visualizations (including graphs, maps, networks, tables, etc.).
